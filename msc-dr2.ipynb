{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4950975,"sourceType":"datasetVersion","datasetId":2871088},{"sourceId":5043891,"sourceType":"datasetVersion","datasetId":2928021}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"train_x_list = \"/kaggle/input/wisdm-data/wisdm/x_train.npy\"\ntrain_y_list = \"/kaggle/input/wisdm-data/wisdm/y_train.npy\"\ntest_x_list = \"/kaggle/input/wisdm-data/wisdm/x_test.npy\"\ntest_y_list = \"/kaggle/input/wisdm-data/wisdm/y_test.npy\"\n'''\ntrain_x_list = \"/kaggle/input/opportunity/OPPORTUNITY/x_train.npy\ntrain_y_list = \"/kaggle/input/opportunity/OPPORTUNITY/y_train.npy\ntest_x_list = \"/kaggle/input/opportunity/OPPORTUNITY/x_test.npy\ntest_y_list = \"/kaggle/input/opportunity/OPPORTUNITY/y_test.npy\n'''\nimport torch\nimport datetime\nimport os\nimport csv\nimport numpy as np\nimport random\nimport shutil\n\nimport argparse\nfrom torch.cuda.amp import autocast as autocast\nfrom torch.cuda.amp import GradScaler\nimport os\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nimport torch.utils.data as Data\nfrom collections import Counter\nfrom imblearn.over_sampling import BorderlineSMOTE\n\nfrom sklearn.model_selection import train_test_split\n\nimport argparse\n\nparser = argparse.ArgumentParser()\n\nimport torch\n\nparser = argparse.ArgumentParser(description=\"Experiment Info and Setings, Model Hyperparameters\")\nparser.add_argument(\"--lambda_cls\", type=float, default=1)\nparser.add_argument(\"--lambda_sc\", type=float, default=2)\nparser.add_argument(\"--lambda_st\", type=float, default=0.2)\nparser.add_argument(\"--lambda_cos_loss\", type=float, default=2)\n# Experiment Info\nparser.add_argument(\"--experiment_date\", type=str, default=f\"{datetime.datetime.now().strftime('%Y%m%d')}\")\nparser.add_argument(\"--experiment_time\", type=str, default=f\"{datetime.datetime.now().strftime('%H:%M:%S')}\")\nparser.add_argument(\"--characteristic\", '-c', type=str, default=\"\")\nparser.add_argument(\"--data\", type=str, default='Sleep-edf')\nparser.add_argument(\"--data_type\", type=str, default='epoch')\nparser.add_argument(\"--scheme\", type=str, default='M_M')\nparser.add_argument(\"--loss_weight\", type=int, default=1)\nparser.add_argument(\"--lstm_layers\", type=int, default=1)\nparser.add_argument(\"--cos_loss\", type=int, default=1)\nparser.add_argument(\"--mha\", type=int, default=1)\nparser.add_argument(\"--mha_length\", type=int, default=8)\nparser.add_argument(\"--mha_head\", type=int, default=2)\nparser.add_argument(\"--mass_ch\", type=str, default='eeg_f4-ler')\nparser.add_argument(\"--downsample\", type=int, default=100)\n# Experiment Hyperparameters\nparser.add_argument(\"--epoch\", type=int, default=150)\nparser.add_argument(\"--lr\", type=float, default=1e-3)\nparser.add_argument(\"--wd\", type=float, default=1e-3)\n\nparser.add_argument(\"--early_stop\", type=int, default=50)\nparser.add_argument(\"--dropout\", type=int, default=0.5)\nparser.add_argument(\"--scheduler\", type=int, default=0)\nparser.add_argument(\"--stride\", type=str, default=2)\nparser.add_argument(\"--preprocess\", type=str, default='robustscale')\n# Model Hyperparameters\nparser.add_argument(\"--batch\", type=int, default=512)\nparser.add_argument(\"--seq_length\", type=int, default=4)\n# GPU\nparser.add_argument(\"--GPU\", type=bool, default=True)\nparser.add_argument(\"--gpu_idx\", type=int, default=-1)\n# Experiment Sbj\nparser.add_argument(\"--range_start\", type=int, default=0)\nparser.add_argument(\"--range_end\", type=int, default=31)\nargs = parser.parse_args(args=[])\n#args = parser.parse_known_args()[0]\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch import default_generator  # type: ignore\nfrom typing import Tuple\nfrom torch import Tensor, Generator\nimport mne\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nfrom numpy.random import shuffle","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:41.201877Z","iopub.execute_input":"2023-11-19T04:51:41.202889Z","iopub.status.idle":"2023-11-19T04:51:41.225527Z","shell.execute_reply.started":"2023-11-19T04:51:41.202855Z","shell.execute_reply":"2023-11-19T04:51:41.224703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def record_name(cv_i):\n    # return args.characteristic + '_Finetuning_Model_' + args.finetuning_model_name + str(args.lr_finetune_network)\n    return args.characteristic + '_CV_' + str(cv_i)\n\n\ndef writelog(file, line):\n    with open(file, 'a', encoding='utf-8') as f:\n        f.write(line + '\\n')\n    print(line + '\\n')\n\ndef label_stage_transition(label_list):\n    for l in range(len(label_list)):\n        label_shape = label_list[l].shape\n        label = label_list[l].flatten()\n        lbl = np.zeros_like(label)\n        for i in range(1, len(label)):\n            if i != len(label) - 1:\n                if label[i] == label[i - 1] and label[i] == label[i + 1]:\n                    lbl[i] = 0\n                else:\n                    lbl[i] = 1\n            else:\n                if label[i] == label[i - 1]:\n                    lbl[i] = 0\n                else:\n                    lbl[i] = 1\n        #cls, count = np.unique(lbl, return_counts=True)\n        #writelog(log_file, f'Lable Count: {dict(zip(cls, count))}')\n        lbl = lbl.reshape(label_shape)\n        label_list[l] = lbl\n    return label_list\n\ndef float_tensor(x):\n    return torch.FloatTensor(x)\n\ndef long_tensor(x):\n    return torch.LongTensor(x)\n\ndef dcn(x):  # detach, cpu, numpy\n    if type(x) == np.ndarray:\n        return x\n    else:\n        return x.detach().cpu().numpy()\n\ndef pb_argmax(x):\n    if len(x.shape) == 1:\n        return (x)\n    else:\n        return np.argmax(x, axis=-1)\n\ndef flatten_1dim(x):\n    if len(x.shape) == 1:\n        return (x)\n    else:\n        return x.flatten()\n\ndef flatten_logit_list(l):\n    for i in range(len(l)):\n        l[i] = l[i].flatten(end_dim=1)\n    return l\n\ndef standardize(x):\n    return (x - x.mean(axis=1)[:, None]) / x.std(axis=1)[:, None]\n\ndef downsample_to_100(x):\n    x = mne.filter.resample(x, down=2.56, axis=-1)\n    return x\n\ndef tr_val_split(idx_tr, idx_val, X_tr_val, Y_tr_val):\n    return X_tr_val[idx_tr], Y_tr_val[idx_tr], X_tr_val[idx_val], Y_tr_val[idx_val]\n\ndef pytorch_sliding_window(x, window_size, step_size=1):\n    # Unfold Dimension to Make Slding Window\n    return x.unfold(0, window_size, step_size)\n\n''' Count Parameters '''\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n''' Loss '''\n\ndef loss_cross_entropy(weight=None, reduction='mean'):  # Take Logit as an Input\n    return nn.CrossEntropyLoss(weight=weight, reduction=reduction)\n\ndef loss_cos_loss(margin=0, reduction='mean'):\n    return nn.CosineEmbeddingLoss(margin=margin, reduction=reduction)\n\ndef loss_mse(reduction='none'):\n    return torch.nn.MSELoss(reduction=reduction)\n\ndef loss_calculate(y_hat, y, y_pre=None, loss_type=None, ignore_index=None, regularizer_const=None, step=None):\n    loss = loss_type(y_hat, y)\n    return loss\n\ndef loss_weight_balance(label):\n    '''\n    Qu et al., (JBHI, 2020)\n    '''\n    label, count = np.unique(label, return_counts=True)\n    ratio_reciprocal = np.reciprocal(count / count.sum())\n    loss_weight = ratio_reciprocal * (len(label) / (ratio_reciprocal.sum()))  # Weight Sum = Num of Label\n    return loss_weight\n\n\n''' Optimizer '''\n\ndef optimizer(params, name='network'):\n    if name == 'network':\n        lr = args.lr_network\n    elif name == 'rss':\n        lr = args.lr_rss\n    opt = Adam(params, lr=lr)\n    # lr_scedule = lr_scheduler.ExponentialLR(opt, gamma=0.96)\n    return opt\n\n\nclass Optimizer():\n    def __init__(self, network):\n        super(Optimizer, self).__init__()\n        self.opt = torch.optim.Adam(network.parameters(),\n                                    lr=args.lr, weight_decay=args.wd)\n\n    def opt_zero_grad(self):\n        self.opt.zero_grad()\n\n    def opt_step(self):\n        self.opt.step()\n\ndef tensor_form(X: list, Y: list):\n    for i in range(len(X)):\n        X[i] = float_tensor(X[i])\n    for i in range(len(Y)):\n        Y[i] = long_tensor((Y[i]))\n    return X, Y\n\nclass tensordataset_w_indices(Dataset[Tuple[Tensor, ...]]):\n    r\"\"\" *** Custom ***\n    Dataset wrapping tensors.\n    Each sample will be retrieved by indexing tensors along the first dimension.\n    Args:\n        *tensors (Tensor): tensors that have the same size of the first dimension.\n    \"\"\"\n    tensors: Tuple[Tensor, ...]\n\n    def __init__(self, *tensors: Tensor) -> None:\n        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors), \"Size mismatch between tensors\"\n        self.tensors = tensors\n\n    def __getitem__(self, index):\n        # (X, Y), idx\n        return tuple(tensor[index] for tensor in self.tensors), index\n\n    def __len__(self):\n        return self.tensors[0].size(0)\n\ndef dataloader_form(X_tr, Y_tr, X_val, Y_val, X_ts, Y_ts):\n    tr_loader = DataLoader(tensordataset_w_indices(X_tr, Y_tr), batch_size=args.batch, shuffle=True, pin_memory=True)\n    val_loader = DataLoader(TensorDataset(X_val, Y_val), batch_size=args.batch, pin_memory=True)\n    ts_loader = DataLoader(TensorDataset(X_ts, Y_ts), batch_size=args.batch, pin_memory=True)\n    return tr_loader, val_loader, ts_loader\n\ndef predict(dataloader, network):\n    Y_new, Y_hat, Y_hat_pb = np.array([]), np.array([]), np.array([[], [], [], [], [], []]).reshape(0, 6)\n    v_t_correct = 0\n    v_t_total = 0\n    test_loss = 0.0\n    test_correct = 0\n    test_total = 0\n    y_true = []\n    y_pred = []\n    for iteration, batch in enumerate(zip(dataloader)):\n        x, y = batch[0]\n        x, y = x.to(device), y.flatten().to(device)\n\n        with torch.no_grad():\n            l_1, l_2, l_2_t = network(x)\n            loss = l_2\n            _, predicted = torch.max(x.data, 1)\n            test_correct += (predicted == y).sum().item()\n            test_total += y.size(0)\n            # 累计测试损失.\n            test_loss += loss.item()\n\n    # 计算测试准确率和损失.\n    test_acc = 100.0 * test_correct / test_total\n    test_loss = test_loss / len(dataloader)\n\n    # 打印测试结果.\n    print('Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(test_loss, test_acc))\n    # 返回测试结果.\n    return test_loss, test_acc\n\nif (torch.cuda.is_available()):\n    device = torch.device(\"cuda\")\n    print(\"使用GPU训练中：{}\".format(torch.cuda.get_device_name()))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"使用CPU训练\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:41.227353Z","iopub.execute_input":"2023-11-19T04:51:41.227850Z","iopub.status.idle":"2023-11-19T04:51:41.263818Z","shell.execute_reply.started":"2023-11-19T04:51:41.227816Z","shell.execute_reply":"2023-11-19T04:51:41.262928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class trian_HAR(Data.Dataset):\n    def __init__(self, filename_x, filename_y):\n        self.filename_x = filename_x\n        self.filename_y = filename_y\n\n    def HAR_data(self):\n        data_x_raw = np.load(self.filename_x)\n\n        data_x = data_x_raw  # (N, C, H, W) (7352, 1, 128, 9)\n        # data_x = np.expand_dims(data_x_raw, 1)\n        data_y = np.load(self.filename_y)\n\n        data_x = data_x.transpose(0, 2, 1)\n        print(\"data_x.shape:\", data_x.shape)\n        data_x = X_window_maker(data_x)\n        data_y = Y_window_maker(data_y)\n        print(\"data_x.shape:\", data_x.shape)\n        print(\"data_y.shape:\", data_y.shape)\n        data_x = torch.tensor(data_x, dtype=torch.float32)\n        data_y = torch.tensor(data_y, dtype=torch.long)\n        train_data, val_data, train_label, val_label = train_test_split(data_x, data_y, test_size=0.1, random_state=42)\n\n        return train_data, train_label, val_data, val_label\n\nclass HAR(Data.Dataset):\n    def __init__(self, filename_x, filename_y):\n        self.filename_x = filename_x\n        self.filename_y = filename_y\n\n    def HAR_data(self):\n        data_x_raw = np.load(self.filename_x)\n        data_y = np.load(self.filename_y)\n        data_x = data_x_raw  # (N, C, H, W) (7352, 1, 128, 9)\n        data_x = data_x.transpose(0, 2, 1)\n        data_x = X_window_maker(data_x)\n        data_y = Y_window_maker(data_y)\n        data_x = torch.tensor(data_x, dtype=torch.float32)\n        data_y = torch.tensor(data_y, dtype=torch.long)\n        # data_x = np.expand_dims(data_x_raw, 1)\n        #print(data_y.type)\n\n        #torch_dataset = Data.TensorDataset(data_x, data_y)\n        return data_x, data_y","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:41.387128Z","iopub.execute_input":"2023-11-19T04:51:41.387892Z","iopub.status.idle":"2023-11-19T04:51:41.398370Z","shell.execute_reply.started":"2023-11-19T04:51:41.387855Z","shell.execute_reply":"2023-11-19T04:51:41.397478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def X_window_maker(x):\n    remain = x.shape[0] % args.seq_length  # Sliding Window and Permute\n    x_window = x[remain:].reshape(-1, args.seq_length, x.shape[-1] * x.shape[-2])  # Slice The Remained From Front\n    return x_window\n\n\ndef Y_window_maker(y):\n    remain = y.shape[0] % args.seq_length\n    y_window = y[remain:].reshape(-1, args.seq_length)\n    return y_window\n\nimport numpy as np\n\n#数据上采样部分\n#data_train = HAR(train_x_list, train_y_list)\n#data_train = HAR_SMOTE(train_x_list, train_y_list)\ndata_train = trian_HAR(train_x_list, train_y_list)\ntrain_data, train_y, val_data, val_y = data_train.HAR_data()\ndata_test = HAR(test_x_list, test_y_list)\ntest_data, test_y = data_test.HAR_data()\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import robust_scale\nfrom mne.filter import filter_data\n\ndef robustscaler(x_tr, x_val, x_ts): \n    scaler = RobustScaler()\n    x_tr_sh = x_tr.shape\n    x_val_sh = x_val.shape\n    x_ts_sh = x_ts.shape\n    x_tr = scaler.fit_transform(x_tr.reshape(-1, x_tr_sh[-1]))\n    x_val = scaler.transform(x_val.reshape(-1, x_val_sh[-1]))\n    x_ts = scaler.transform(x_ts.reshape(-1, x_ts_sh[-1]))\n    x_tr = x_tr.reshape(*x_tr_sh)\n    x_val = x_val.reshape(*x_val_sh)\n    x_ts = x_ts.reshape(*x_ts_sh)\n    return x_tr, x_val, x_ts\n\n\nX_tr, X_val, X_ts = robustscaler(train_data, val_data, test_data)\n[X_tr, X_val, X_ts], [Y_tr_org, Y_val_org, Y_ts_org] = tensor_form([X_tr, X_val, X_ts], [train_y, val_y, test_y])\nY_tr_t, Y_val_t, Y_ts_t = label_stage_transition([Y_tr_org, Y_val_org, Y_ts_org])\n[], [Y_tr_t, Y_val_t, Y_ts_t] = tensor_form([], [Y_tr_t, Y_val_t, Y_ts_t])\nloss_weight_org = float_tensor(loss_weight_balance(Y_tr_org)).to(device)  # tensor array\nloss_weight_t = float_tensor(loss_weight_balance(Y_tr_t)).to(device)  # tensor array\nloss_weight_dict = {'org': loss_weight_org, 'trans': loss_weight_t}\n\ntr_loader, val_loader, ts_loader = dataloader_form(X_tr, Y_tr_org, X_val, Y_val_org, X_ts, Y_ts_org)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:41.400281Z","iopub.execute_input":"2023-11-19T04:51:41.400566Z","iopub.status.idle":"2023-11-19T04:51:42.950049Z","shell.execute_reply.started":"2023-11-19T04:51:41.400522Z","shell.execute_reply":"2023-11-19T04:51:42.948934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n#from retention import MultiScaleRetention\nimport math\nimport torch\nimport torch.nn as nn\ndevice = torch.device(\"cuda\")\ndef fixed_pos_embedding(x):\n    seq_len, dim = x.shape\n    inv_freq = 1.0 / (10000 ** (torch.arange(0, dim) / dim))\n    sinusoid_inp = (\n        torch.einsum(\"i , j -> i j\", torch.arange(0, seq_len, dtype=torch.float), inv_freq).to(x)\n    )\n    return torch.sin(sinusoid_inp), torch.cos(sinusoid_inp)\n\ndef rotate_every_two(x):\n    x1 = x[:, :, ::2]\n    x2 = x[:, :, 1::2]\n\n    x = torch.stack((-x2, x1), dim=-1)\n    return x.flatten(-2)\n\n    # in einsum notation: rearrange(x, '... d j -> ... (d j)')\\\n\ndef duplicate_interleave(m):\n    \"\"\"\n    A simple version of `torch.repeat_interleave` for duplicating a matrix while interleaving the copy.\n    \"\"\"\n    dim0 = m.shape[0]\n    m = m.view(-1, 1)  # flatten the matrix\n    m = m.repeat(1, 2)  # repeat all elements into the 2nd dimension\n    m = m.view(dim0, -1)  # reshape into a matrix, interleaving the copy\n    return m\n\ndef apply_rotary_pos_emb(x, sin, cos, scale=1):\n    sin, cos = map(lambda t: duplicate_interleave(t * scale), (sin, cos))\n    # einsum notation for lambda t: repeat(t[offset:x.shape[1]+offset,:], \"n d -> () n () (d j)\", j=2)\n    return (x * cos) + (rotate_every_two(x) * sin)\n\nclass XPOS(nn.Module):\n    def __init__(\n            self, head_dim, scale_base=512\n    ):\n        super().__init__()\n        self.head_dim = head_dim\n        self.scale_base = scale_base\n        self.register_buffer(\n            \"scale\", (torch.arange(0, head_dim, 2) + 0.4 * head_dim) / (1.4 * head_dim)\n        )\n\n    def forward(self, x, offset=0, downscale=False):\n        length = x.shape[1]\n        min_pos = 0\n        max_pos = length + offset + min_pos\n        scale = self.scale ** torch.arange(min_pos, max_pos, 1).to(self.scale).div(self.scale_base)[:, None]\n        sin, cos = fixed_pos_embedding(scale)\n\n        if scale.shape[0] > length:\n            scale = scale[-length:]\n            sin = sin[-length:]\n            cos = cos[-length:]\n\n        if downscale:\n            scale = 1 / scale\n\n        x = apply_rotary_pos_emb(x, sin, cos, scale)\n        return x\n\n    def forward_reverse(self, x, offset=0, downscale=False):\n        length = x.shape[1]\n        min_pos = -(length + offset) // 2\n        max_pos = length + offset + min_pos\n        scale = self.scale ** torch.arange(min_pos, max_pos, 1).to(self.scale).div(self.scale_base)[:, None]\n        sin, cos = fixed_pos_embedding(scale)\n\n        if scale.shape[0] > length:\n            scale = scale[-length:]\n            sin = sin[-length:]\n            cos = cos[-length:]\n\n        if downscale:\n            scale = 1 / scale\n\n        x = apply_rotary_pos_emb(x, -sin, cos, scale)\n        return x\nclass SimpleRetention(nn.Module):\n    def __init__(self, hidden_size, gamma, head_size=None, double_v_dim=False):\n        \"\"\"\n        Simple retention mechanism based on the paper\n        \"Retentive Network: A Successor to Transformer for Large Language Models\"[https://arxiv.org/pdf/2307.08621.pdf]\n        \"\"\"\n        super(SimpleRetention, self).__init__()\n\n        self.hidden_size = hidden_size\n        if head_size is None:\n            head_size = hidden_size\n        self.head_size = head_size\n\n        self.v_dim = head_size * 2 if double_v_dim else head_size\n        self.gamma = gamma\n        self.W_Q = nn.Parameter(torch.randn(hidden_size, head_size) / hidden_size)\n        self.W_K = nn.Parameter(torch.randn(hidden_size, head_size) / hidden_size)\n        self.W_V = nn.Parameter(torch.randn(hidden_size, self.v_dim) / hidden_size)\n\n        self.xpos = XPOS(head_size)\n\n    def forward(self, X):\n        \"\"\"\n        Parallel (default) representation of the retention mechanism.\n        X: (batch_size, sequence_length, hidden_size)\n        \"\"\"\n        sequence_length = X.shape[1]\n        D = self._get_D(sequence_length)\n\n        Q = (X @ self.W_Q)\n        K = (X @ self.W_K)\n\n        Q = self.xpos(Q)\n        K = self.xpos(K, downscale=True)\n\n        V = X @ self.W_V\n        Q, K, V ,D= Q.to(device), K.to(device), V.to(device),D.to(device)\n\n        ret = (Q @ K.permute(0, 2, 1)) * D.unsqueeze(0)\n\n        return ret @ V\n\n    def forward_recurrent(self, x_n, s_n_1, n):\n        \"\"\"\n        Recurrent representation of the retention mechanism.\n        x_n: (batch_size, 1, hidden_size)\n        s_n_1: (batch_size, hidden_size, v_dim)\n        \"\"\"\n\n        Q = (x_n @ self.W_Q)\n        K = (x_n @ self.W_K)\n\n        Q = self.xpos(Q, n+1)\n        K = self.xpos(K, n+1, downscale=True)\n\n        V = x_n @ self.W_V\n\n        # K: (batch_size, 1, hidden_size)\n        # V: (batch_size, 1, v_dim)\n        # s_n = gamma * s_n_1 + K^T @ V\n\n        s_n = self.gamma * s_n_1 + (K.transpose(-1, -2) @ V)\n\n        return (Q @ s_n), s_n\n\n    def forward_chunkwise(self, x_i, r_i_1, i):\n        \"\"\"\n        Chunkwise representation of the retention mechanism.\n        x_i: (batch_size, chunk_size, hidden_size)\n        r_i_1: (batch_size, hidden_size, v_dim)\n        \"\"\"\n        batch, chunk_size, _ = x_i.shape\n        D = self._get_D(chunk_size)\n        x_i = x_i.to(self.W_Q.device) \n        self.W_Q = self.W_Q.to(x_i.device)\n        self.W_K = self.W_K.to(x_i.device)\n        Q = (x_i @ self.W_Q)\n        K = (x_i @ self.W_K)\n\n        Q = self.xpos(Q, i * chunk_size)\n        K = self.xpos(K, i * chunk_size, downscale=True)\n        \n        V = x_i @ self.W_V\n\n        #print(r_i_1.shape)\n        r_i_1 = r_i_1[:K.shape[0]]  \n        r_i =(K.transpose(-1, -2) @ (V * D[-1].view(1, chunk_size, 1))) + (self.gamma ** chunk_size) * r_i_1\n\n        inner_chunk = ((Q @ K.transpose(-1, -2)) * D.unsqueeze(0)) @ V\n\n        #e[i,j] = gamma ** (i+1)\n        e = torch.zeros(batch, chunk_size, 1)\n\n        for _i in range(chunk_size):\n            e[:, _i, :] = self.gamma ** (_i + 1)\n\n        cross_chunk = (Q @ r_i_1) * e\n\n        return inner_chunk + cross_chunk, r_i\n\n    def _get_D(self, sequence_length):\n        n = torch.arange(sequence_length).unsqueeze(1)\n        m = torch.arange(sequence_length).unsqueeze(0)\n\n        # Broadcast self.gamma ** (n - m) with appropriate masking to set values where n < m to 0\n        D = (self.gamma ** (n - m)) * (n >= m).float()  #this results in some NaN when n is much larger than m\n        # fill the NaN with 0\n        D[D != D] = 0\n\n        return D\n\n\n\nclass MultiScaleRetention(nn.Module):\n    def __init__(self, hidden_size, heads, double_v_dim=False):\n        \"\"\"\n        Multi-scale retention mechanism based on the paper\n        \"Retentive Network: A Successor to Transformer for Large Language Models\"[https://arxiv.org/pdf/2307.08621.pdf]\n        \"\"\"\n        super(MultiScaleRetention, self).__init__()\n        self.hidden_size = hidden_size\n        self.v_dim = hidden_size * 2 if double_v_dim else hidden_size\n        self.heads = heads\n        assert hidden_size % heads == 0, \"hidden_size must be divisible by heads\"\n        self.head_size = hidden_size // heads\n        self.head_v_dim = hidden_size * 2 if double_v_dim else hidden_size\n\n        self.gammas = (1 - torch.exp(torch.linspace(math.log(1/32), math.log(1/512), heads))).detach().cpu().tolist()\n\n        self.swish = lambda x: x * torch.sigmoid(x)\n        self.W_G = nn.Parameter(torch.randn(hidden_size, self.v_dim) / hidden_size)\n        self.W_O = nn.Parameter(torch.randn(self.v_dim, hidden_size) / hidden_size)\n        self.group_norm = nn.GroupNorm(heads, self.v_dim)\n\n        self.retentions = nn.ModuleList([\n            SimpleRetention(self.hidden_size, gamma, self.head_size, double_v_dim) for gamma in self.gammas\n        ])\n\n    def forward(self, X):\n        \"\"\"\n        parallel representation of the multi-scale retention mechanism\n        \"\"\"\n\n        # apply each individual retention mechanism to X\n        Y = []\n        for i in range(self.heads):\n            Y.append(self.retentions[i](X))\n\n        Y = torch.cat(Y, dim=2)\n        Y_shape = Y.shape\n        Y = self.group_norm(Y.reshape(-1, self.v_dim)).reshape(Y_shape)\n\n        return (self.swish(X @ self.W_G) * Y) @ self.W_O\n\n    def forward_recurrent(self, x_n, s_n_1s, n):\n        \"\"\"\n        recurrent representation of the multi-scale retention mechanism\n        x_n: (batch_size, 1, hidden_size)\n        s_n_1s: (batch_size, heads, head_size, head_size)\n\n        \"\"\"\n\n        # apply each individual retention mechanism to a slice of X\n        Y = []\n        s_ns = []\n        for i in range(self.heads):\n            y, s_n = self.retentions[i].forward_recurrent(\n                x_n[:, :, :], s_n_1s[i], n\n            )\n            Y.append(y)\n            s_ns.append(s_n)\n\n        Y = torch.cat(Y, dim=2)\n        Y_shape = Y.shape\n        Y = self.group_norm(Y.reshape(-1, self.v_dim)).reshape(Y_shape)\n\n        return (self.swish(x_n @ self.W_G) * Y) @ self.W_O, s_ns\n\n    def forward_chunkwise(self, x_i, r_i_1s, i):\n        \"\"\"\n        chunkwise representation of the multi-scale retention mechanism\n        x_i: (batch_size, chunk_size, hidden_size)\n        r_i_1s: (batch_size, heads, head_size, head_size)\n        \"\"\"\n        batch, chunk_size, _ = x_i.shape\n\n        # apply each individual retention mechanism to a slice of X\n        Y = []\n        r_is = []\n        for j in range(self.heads):\n            y, r_i = self.retentions[j].forward_chunkwise(\n                x_i[:, :, :], r_i_1s[j], i\n            )\n            Y.append(y)\n            r_is.append(r_i)\n\n\n        Y = torch.cat(Y, dim=2)\n        Y_shape = Y.shape\n        Y = self.group_norm(Y.reshape(-1, self.v_dim)).reshape(Y_shape)\n        x_i = x_i.to(self.W_G.device)\n        return (self.swish(x_i @ self.W_G) * Y) @ self.W_O, r_is\n\nclass RetNet(nn.Module):\n    def __init__(self, layers, hidden_dim, ffn_size, heads, double_v_dim=False):\n        super(RetNet, self).__init__()\n        self.layers = layers\n        self.hidden_dim = hidden_dim\n        self.ffn_size = ffn_size\n        self.heads = heads\n        self.v_dim = hidden_dim * 2 if double_v_dim else hidden_dim\n\n        self.retentions = nn.ModuleList([\n            MultiScaleRetention(hidden_dim, heads, double_v_dim)\n            for _ in range(layers)\n        ])\n        self.ffns = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(hidden_dim, ffn_size),\n                nn.GELU(),\n                nn.Linear(ffn_size, hidden_dim)\n            )\n            for _ in range(layers)\n        ])\n        self.layer_norms_1 = nn.ModuleList([\n            nn.LayerNorm(hidden_dim)\n            for _ in range(layers)\n        ])\n        self.layer_norms_2 = nn.ModuleList([\n            nn.LayerNorm(hidden_dim)\n            for _ in range(layers)\n        ])\n\n    def forward(self, X):\n        \"\"\"\n        X: (batch_size, sequence_length, hidden_size)\n        \"\"\"\n        for i in range(self.layers):\n            Y = self.retentions[i](self.layer_norms_1[i](X)) + X\n\n            X = self.ffns[i](self.layer_norms_2[i](Y)) + Y\n\n        return X\n\n    def forward_recurrent(self, x_n, s_n_1s, n):\n        \"\"\"\n        X: (batch_size, sequence_length, hidden_size)\n        s_n_1s: list of lists of tensors of shape (batch_size, hidden_size // heads, hidden_size // heads)\n\n        \"\"\"\n        s_ns = []\n        for i in range(self.layers):\n            # list index out of range\n            o_n, s_n = self.retentions[i].forward_recurrent(self.layer_norms_1[i](x_n), s_n_1s[i], n)\n            y_n = o_n + x_n\n            s_ns.append(s_n)\n            x_n = self.ffns[i](self.layer_norms_2[i](y_n)) + y_n\n\n        return x_n, s_ns\n\n    def forward_chunkwise(self, x_i, r_i_1s, i):\n        \"\"\"\n        X: (batch_size, sequence_length, hidden_size)\n        r_i_1s: list of lists of tensors of shape (batch_size, hidden_size // heads, hidden_size // heads)\n\n        \"\"\"\n        r_is = []\n        for j in range(self.layers):\n            o_i, r_i = self.retentions[j].forward_chunkwise(self.layer_norms_1[j](x_i), r_i_1s[j], i)\n            y_i = o_i + x_i\n            r_is.append(r_i)\n            x_i = self.ffns[j](self.layer_norms_2[j](y_i)) + y_i\n\n        return x_i, r_is\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:42.951412Z","iopub.execute_input":"2023-11-19T04:51:42.951728Z","iopub.status.idle":"2023-11-19T04:51:43.143532Z","shell.execute_reply.started":"2023-11-19T04:51:42.951696Z","shell.execute_reply":"2023-11-19T04:51:43.142716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#batch_size = 512\n#train_dataloader = DataLoader(dataset=tr_loader, batch_size=batch_size, pin_memory=True, shuffle=True,drop_last=True, num_workers=2,)\n#test_dataloader = DataLoader(dataset=ts_loader, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\n#val_dataloader = DataLoader(dataset=val_loader, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\ndef train(network, tr_loader, val_loader, optimizer1, num_epochs=50, loss_weight=None, Y_t=None):\n    # 定义损失函数和优化器.\n\n    train_loss_list = []\n    train_acc_list = []\n    val_loss_list = []\n    val_acc_list = []\n    criterion1 = nn.CrossEntropyLoss()\n    # 定义在验证集上表现最好的模型准确率和损失.\n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    Best_epoch = 0\n    #定义存储最佳模型参数的变量.\n    best_model_params = None\n    # 开始训练模型.\n    for epoch in range(num_epochs):\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        network.train()\n        \n        for (x, y), idx in tr_loader:\n            x, y, y_t = x.to(device), y.flatten().to(device), Y_t[idx].flatten().to(device)\n            \n            optimizer1.opt_zero_grad()\n            #optimizer2.zero_grad()\n\n            output = network(x)\n\n            loss = args.lambda_cls*loss_cross_entropy(weight=loss_weight['org'])(output, y)\n            loss_cos = args.lambda_cls*args.lambda_cos_loss*loss_cos_loss()(output, F.one_hot(y, num_classes=6), torch.ones_like(y))\n            loss = loss+loss_cos\n            _, predicted = torch.max(output.data, 1)\n            train_correct += (predicted == y).sum().item()\n            train_total += y.size(0)\n            # 累计训练损失\n            #scaler.scale(loss).backward()\n            #scaler.step(optimizer1)\n\n            #scaler.update()\n            loss.backward()\n            optimizer1.opt_step()\n            #optimizer2.step()\n            train_loss += loss.item()\n            print(\">\", end=\"\")\n        # 计算训练准确率和损失.\n        train_acc = 100.0 * train_correct / train_total\n        train_loss = train_loss / len(tr_loader)\n\n        # 在验证集上验证模型.\n        #val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        network.eval()\n        with torch.no_grad():\n            for iteration, batch in enumerate(zip(val_loader)):\n\n                x, y = batch[0]\n                x, y = x.to(device), y.flatten().to(device)\n\n                # 前向传播.\n                l_2 = network(x)\n                # 计算损失和准确率.\n\n                _, predicted = torch.max(l_2.data, 1)\n                val_correct += (predicted == y).sum().item()\n                val_total += y.size(0)\n\n                # 累计验证损失.\n                #val_loss += loss.item()\n\n        # 计算验证准确率和损失.\n        val_acc = 100.0 * val_correct / val_total\n        #val_loss = val_loss / len(val_loader)\n        if val_acc > best_val_acc:\n            Best_epoch = epoch + 1\n            best_val_acc = val_acc\n            #best_val_loss = val_loss\n            best_model_params = network.state_dict()\n\n        print()\n        # 打印训练和验证结果.\n        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%,Val Acc: {:.2f}%'\n              .format(epoch + 1, num_epochs, train_loss, train_acc, val_acc))\n\n        # 保存训练和验证结果.\n        train_loss_list.append(train_loss)\n        train_acc_list.append(train_acc)\n        #val_loss_list.append(val_loss)\n        val_acc_list.append(val_acc)\n    print(\"The best epoch:\", Best_epoch, \"    Acc:\", best_val_acc)\n    network.load_state_dict(best_model_params)\n    # 返回训练和验证结果.\n    return network.eval(), train_loss_list, train_acc_list, val_acc_list","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:43.145041Z","iopub.execute_input":"2023-11-19T04:51:43.145299Z","iopub.status.idle":"2023-11-19T04:51:43.164862Z","shell.execute_reply.started":"2023-11-19T04:51:43.145276Z","shell.execute_reply":"2023-11-19T04:51:43.164009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import copy\nimport math\n#from utils import *\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nimport torch.nn as nn\n\n\nclass Classifier(nn.Module):\n    def __init__(self, in_f, out_f):\n        '''\n        Classify FE feature\n        '''\n        super(Classifier, self).__init__()\n        self.linear_1 = nn.Linear(in_f, out_f)  # 创建一个nn.Linear实例，并将其赋值给self.linear_1，输入的参数为in_f和out_f\n\n    def forward(self, x):\n        x = self.linear_1(x)  # 将输入张量x通过self.linear_1处理得到输出张量\n        return x\n\n\n\nclass MSNN_Feature_Embedding_Two_Way(nn.Module):\n    def __init__(self):\n        super(MSNN_Feature_Embedding_Two_Way, self).__init__()\n        # 定义卷积、可分离卷积\n        conv = lambda in_f, out_f, kernel, s=None: nn.Sequential(nn.Conv1d(in_f, out_f, (kernel,), stride=s),\n                                                                 nn.BatchNorm1d(out_f), nn.LeakyReLU())\n        sepconv_same = lambda in_f, out_f, kernel: nn.Sequential(\n            nn.Conv1d(in_f, out_f, (kernel,), padding=int(kernel / 2), groups=in_f),\n            nn.Conv1d(out_f, out_f, (1,)), nn.BatchNorm1d(out_f), nn.LeakyReLU())\n\n        self.conv_A_0 = conv(1, 4, 5, 1)\n        self.sepconv_A_1 = sepconv_same(4, 16, 9)\n        self.sepconv_A_2 = sepconv_same(16, 32, 5)\n        self.sepconv_A_3 = sepconv_same(32, 64, 3) \n\n        self.conv_B_0 = conv(1, 4, 10, 1)  \n        self.sepconv_B_1 = sepconv_same(4, 16, 9) \n        self.sepconv_B_2 = sepconv_same(16, 32, 5) \n        self.sepconv_B_3 = sepconv_same(32, 64, 3) \n        \n        self.conv_C_0 = conv(1, 4, 20, 1)  \n        self.sepconv_C_1 = sepconv_same(4, 16, 9) \n        self.sepconv_C_2 = sepconv_same(16, 32, 5) \n        self.sepconv_C_3 = sepconv_same(32, 64, 3) \n        #self.ATT = EfficientChannelAttention(112)\n        self.gap = nn.AdaptiveAvgPool1d(args.mha_length)  \n\n    def one_way(self, conv_0, sepconv_1, sepconv_2, sepconv_3, x):\n        b, l, t = x.shape\n        x = x.reshape(-1, 1, t) #[B*F,1,T]\n        x = conv_0(x)\n        x = sepconv_1(x)\n        x1 = x\n        x = sepconv_2(x) \n        x2 = x\n        x = sepconv_3(x) \n        x3 = x\n        #n = self.ATT(n)\n        x = self.gap(torch.cat([x1, x2, x3], 1))\n        x = x.reshape(b, l, *x.shape[-2:]) \n\n        return x , x3\n    def one_way_end(self, conv_0, sepconv_1, sepconv_2, sepconv_3, x):\n        b, l, t = x.shape\n        x = x.reshape(-1, 1, t) #[B*F,1,T]\n        x = conv_0(x)\n        x = sepconv_1(x)\n        x1 = x\n        x = sepconv_2(x) \n        x2 = x\n        x = sepconv_3(x) \n        #t = self.ATT(x)\n        #if att !=None:\n            #x = self.ATT(x+att)\n        #att = t+x\n        #x = x + self.seq_trans(self.pe, x) \n        #x = x.permute(-1, 0, 1) #[T,B*F,F]\n        #x = mha_ff(x).permute(1, -1, 0) \n        print(x.shape)\n        return x\n\n    def forward(self, x):\n        #c= self.one_way_end(self.conv_C_0, self.sepconv_C_1, self.sepconv_C_2, self.sepconv_C_3, x)\n        x_A ,a= self.one_way(self.conv_A_0, self.sepconv_A_1, self.sepconv_A_2, self.sepconv_A_3, x) \n        x_B ,b= self.one_way(self.conv_B_0, self.sepconv_B_1, self.sepconv_B_2, self.sepconv_B_3, x)\n        x_C ,c= self.one_way(self.conv_C_0, self.sepconv_C_1, self.sepconv_C_2, self.sepconv_C_3, x)\n        x = torch.cat((x_A, x_B,x_C), dim=-2) \n        return x\n#############################################################################################################################\n\nclass Context_Encoder(nn.Module):\n    def __init__(self, f, h):\n        super(Context_Encoder, self).__init__()\n        self.dropout_1 = nn.Dropout(0.2) \n        self.dropout_2 = nn.Dropout(0.4) \n        self.MR1 = RetNet(layers=1, hidden_dim=f, ffn_size=h, heads=16, double_v_dim=False)\n\n    def forward(self, x): \n        h = self.MR1(x)  \n        h = self.dropout_1(h) \n        h = h+x\n        h = self.dropout_2(h) \n        return h\n#############################################################################################################################\n\nclass Model(nn.Module):\n    def __init__(self, x, num_classes=17):\n        super(Model, self).__init__()\n        self.FE = MSNN_Feature_Embedding_Two_Way().to(device)\n        with torch.no_grad():\n            b, l, f, t = self.FE(x).shape \n            feature_size = f * t  \n            embedding_size = int(feature_size / 2)\n\n        self.Context_Encoder = Context_Encoder(feature_size, embedding_size).to(device) \n        with torch.no_grad(): \n            x = self.FE(x)\n            x = x.flatten(start_dim=2)\n            feature_size2 = self.Context_Encoder(x).shape[-1]\n        self.project_f = nn.Linear(feature_size2,768) \n        self.dropout = nn.Dropout()\n        self.cls = Classifier(feature_size2, 6)\n\n    def forward(self, x):\n        x = x.to(device)\n\n        #b, l, f = x.shape  # 计算输入张量x的形状\n        #x = x.view(-1,113, 30)\n\n        #x = self.res1(x)\n        \n        x = self.FE(x)\n\n        #print(x.shape)\n        b, l, f, t = x.shape  # 计算输入张量x的形状\n        x = x.view(b,l, -1)\n\n\n        h = network.Context_Encoder.forward(x)\n        l_2 = network.cls(h.to(device)) \n        l_2 = l_2.flatten(end_dim=1)\n\n        return l_2","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:43.168067Z","iopub.execute_input":"2023-11-19T04:51:43.168358Z","iopub.status.idle":"2023-11-19T04:51:43.195434Z","shell.execute_reply.started":"2023-11-19T04:51:43.168333Z","shell.execute_reply":"2023-11-19T04:51:43.194506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_t = {'tr': Y_tr_t, 'val': Y_val_t, 'ts': Y_ts_t}\nnetwork = Model(x=tr_loader.dataset.tensors[0][:2].to(device)).to(device)\nimport time\nopt = Optimizer(network)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:43.196501Z","iopub.execute_input":"2023-11-19T04:51:43.196828Z","iopub.status.idle":"2023-11-19T04:51:43.639977Z","shell.execute_reply.started":"2023-11-19T04:51:43.196803Z","shell.execute_reply":"2023-11-19T04:51:43.638960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\nmodel, train_loss_list, train_acc_list, val_acc_list = \\\n    train(network=network, tr_loader=tr_loader, val_loader=val_loader, num_epochs=50, optimizer1=opt,\n          loss_weight=loss_weight_dict, Y_t=Y_t['tr'])\nend_time = time.time()\nuse_time = end_time - start_time\nprint(\"Train and val complete in {:.0f}m {:.0f}s\".format(use_time // 60, use_time % 60))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:51:43.641151Z","iopub.execute_input":"2023-11-19T04:51:43.641445Z","iopub.status.idle":"2023-11-19T04:56:44.594470Z","shell.execute_reply.started":"2023-11-19T04:51:43.641419Z","shell.execute_reply":"2023-11-19T04:56:44.593535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_loss_and_acc(train_loss_list, train_acc_list, val_acc_list):\n    # 绘制训练和验证损失\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_loss_list, label='train_loss')\n    #plt.plot(val_loss_list, label='val_loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    # 绘制训练和验证准确率\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_acc_list, label='train_acc')\n    plt.plot(val_acc_list, label='val_acc')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\n\nplot_loss_and_acc(train_loss_list, train_acc_list, val_acc_list)\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:56:44.595783Z","iopub.execute_input":"2023-11-19T04:56:44.596120Z","iopub.status.idle":"2023-11-19T04:56:45.201763Z","shell.execute_reply.started":"2023-11-19T04:56:44.596093Z","shell.execute_reply":"2023-11-19T04:56:45.200866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\ndef test_final(model, test_dataloader,loss_weight = 0.007):\n    # 将模型设置为测试模式.\n    model.eval()\n\n       # 定义损失函数和优化器.\n    criterion1 = nn.CrossEntropyLoss()\n    criterion2 = CenterLoss(6, 6).to(device)\n\n    loss_weight=0.007\n    # 在测试集上测试模型.\n    test_loss = 0.0\n    test_correct = 0\n    test_total = 0\n    y_true = []\n    y_pred = []\n    num_classes = 6\n    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)  # 创建混淆矩阵\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(test_dataloader):\n            # 将输入和标签数据转换为Tensor并放到GPU上（如果有的话）.\n            #inputs = inputs.to(device)\n            #labels = labels.to(device)\n            outputs= model(inputs.type(torch.float32))\n            labels = labels.long()\n            labels = (labels.clone().detach()-1).to(device).squeeze()\n\n            # 前向传播.\n            #outputs = model(inputs)\n            pre_lab = torch.argmax(outputs, 1)\n            # 计算损失和准确率.\n            #loss = criterion1(outputs, labels)\n            loss = criterion1(outputs, labels) + loss_weight * criterion2(labels, outputs)\n            _, predicted = torch.max(\n                                     outputs.data, 1)\n            test_correct += (predicted == labels).sum().item()\n            test_total += labels.size(0)\n\n            # 累计测试损失.\n            test_loss += loss.item()\n            y_true.extend(labels.tolist())\n            y_pred.extend(pre_lab.tolist())\n            conf_matrix += confusion_matrix(labels.cpu(), pre_lab.cpu(), labels=range(num_classes))\n    report = classification_report(y_true, y_pred,digits=4)\n    g_mean = np.sqrt(np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n    g_mean = np.mean(g_mean)\n\n    # 更新分类报告\n    report += '\\nG-mean: {:.4f}'.format(g_mean)\n    # 计算测试准确率和损失.\n    test_acc = 100.0 * test_correct / test_total\n    test_loss = test_loss / len(test_dataloader)\n\n    # 打印测试结果.\n    print('Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(test_loss, test_acc))\n    print(report)\n    # 返回测试结果.\n    return test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:56:45.203475Z","iopub.execute_input":"2023-11-19T04:56:45.203892Z","iopub.status.idle":"2023-11-19T04:56:45.217491Z","shell.execute_reply.started":"2023-11-19T04:56:45.203856Z","shell.execute_reply":"2023-11-19T04:56:45.216494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc=test_final(model, ts_dataloader,loss_weight = 0.007)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:56:45.218834Z","iopub.execute_input":"2023-11-19T04:56:45.219172Z","iopub.status.idle":"2023-11-19T04:56:45.403508Z","shell.execute_reply.started":"2023-11-19T04:56:45.219140Z","shell.execute_reply":"2023-11-19T04:56:45.402138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.font_manager as font_manager\nimport shutil\nimport matplotlib\nimport matplotlib.font_manager as fm\n\n\nfont_dirs = '/kaggle/input/timesttf/times.ttf'\n#font_paths = fm.findSystemFonts() # 查系统中可用的字体X件路径\nfm.fontManager.addfont(font_dirs)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:56:45.404655Z","iopub.status.idle":"2023-11-19T04:56:45.405166Z","shell.execute_reply.started":"2023-11-19T04:56:45.404905Z","shell.execute_reply":"2023-11-19T04:56:45.404931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\nfrom matplotlib.ticker import PercentFormatter\nclass DrawConfusionMatrix:\n    def __init__(self, labels_name, normalize=True):\n        self.normalize = normalize\n        self.labels_name = labels_name\n        self.num_classes = len(labels_name)\n        self.matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"float32\")\n        self.class_counts_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int32\")\n\n    def update(self, labels, predicts):\n        for predict, label in zip(labels, predicts):\n            self.matrix[label, predict] += 1\n            self.class_counts_matrix[label, predict] += 1\n\n    def getMatrix(self, normalize=True):\n        if normalize:\n            per_sum = self.matrix.sum(axis=1)  # 计算每行的和，用于百分比计算\n            for i in range(self.num_classes):\n                self.matrix[i] = (self.matrix[i] / per_sum[i])  # 百分比转换\n            self.matrix = np.around(self.matrix, 4)  # 保留4位小数点\n            self.matrix[np.isnan(self.matrix)] = 0.0  # 可能存在NaN，将其设为0\n        return self.matrix\n\n    def drawMatrix(self):\n        self.matrix = self.getMatrix(self.normalize)\n        font = FontProperties(family='serif', style='normal', weight='normal', size=10)\n        plt.figure(dpi=480)\n        plt.imshow(self.matrix, cmap=plt.cm.Blues)  # 仅画出颜色格子，没有值\n        plt.title(\"WISDM\", fontproperties=font)  # 标题\n        plt.xlabel(\"Predict label\", fontproperties=font)\n        plt.ylabel(\"Truth label\", fontproperties=font)\n\n        plt.yticks(range(self.num_classes), self.labels_name, fontproperties=font)  # y轴标签\n        plt.xticks(range(self.num_classes), self.labels_name, rotation=30, fontproperties=font)  # x轴标签\n        thresh = self.matrix.max() / 2.\n\n        for x in range(self.num_classes):\n            for y in range(self.num_classes):\n                count = self.class_counts_matrix[y, x]\n                value = str(format('%.2f' % float(self.matrix[y, x] * 100.00))) + '%'  # 数值处理\n                #text = f\"{count}\\n{value}\"\n                text = count\n                plt.text(x, y-0.13, text, verticalalignment='center',\n                         horizontalalignment='center',\n                         color=\"white\" if self.matrix[y, x] > thresh else \"black\", fontproperties=font, fontsize=8)  # 写值\n                plt.text(x, y+0.13, value, verticalalignment='center',\n                         horizontalalignment='center',\n                         color=\"white\" if self.matrix[y, x] > thresh else \"black\", fontproperties=font, fontsize=8)  # 写值\n\n        plt.tight_layout()  # 自动调整子图参数，使之填充整个图像区域\n\n        #色条\n        plt.colorbar(format=PercentFormatter(xmax=1, decimals=0, symbol='%', is_latex=False))\n        plt.savefig('./ConfusionMatrix.png', bbox_inches='tight')  # bbox_inches='tight'可确保标签信息显示全\n        plt.show()\n\n\ndef printMatrix(test_loader, model):\n    #labels_name = ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n    #labels_name=[\"Walking\", \"Upstairs\", \"Downstairs\", \"Sitting\", \"Standing\", \"Laying\"]\n    labels_name = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18']\n    drawconfusionmatrix = DrawConfusionMatrix(labels_name=labels_name)  # 实例化\n    for index, (imgs, labels) in enumerate(test_loader, 1):\n        labels_pd = model(imgs.float())\n        predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)  # array([0,5,1,6,3,...],dtype=int64)\n        labels_np = labels.numpy()  # array([0,5,0,6,2,...],dtype=int64)\n        drawconfusionmatrix.update(labels_np, predict_np)  # 将新批次的predict和label更新（保存）\n\n    drawconfusionmatrix.drawMatrix()  # 根据所有predict和label，画出混淆矩阵\n\n    confusion_mat = drawconfusionmatrix.getMatrix()  # 你也可以使用该函数获取混淆矩阵(ndarray)\n    print(confusion_mat)\n\nprint(\"开始绘制混淆矩阵\")\nprintMatrix(ts_dataloader, model)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:56:45.407568Z","iopub.status.idle":"2023-11-19T04:56:45.408077Z","shell.execute_reply.started":"2023-11-19T04:56:45.407815Z","shell.execute_reply":"2023-11-19T04:56:45.407842Z"},"trusted":true},"execution_count":null,"outputs":[]}]}